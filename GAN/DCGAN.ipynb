{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  [DCGAN: Deep Convolutional Generative Adversarial Networks](https://arxiv.org/abs/1511.06434)\n",
    "\n",
    "**DCGAN** is one of the most popular and succesful network design for GAN. It mainly composes of convolution layers without max pooling or fully connected layers. It uses strided convolutions and transposed convolutions for the downsampling and the upsampling respectively.\n",
    "\n",
    "**Network Design of DCGAN:**\n",
    "\n",
    "* Replace all pooling layers with strided convolutions.\n",
    "* Remove all fully connected layers.\n",
    "* Use transposed convolutions for upsampling.\n",
    "* Use Batch Normalization after every layer except after the output layer of the generator and the input layer of the discriminator.\n",
    "* Use ReLU non-linearity for each layer in the generator except for output layer use tanh.\n",
    "* Use Leaky-ReLU non-linearity for each layer of the disciminator excpet for output layer use sigmoid.\n",
    "\n",
    "\n",
    "![](./Sources/dcgan.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "UAhsb1yoYyES"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "aoJVNOSoZeUV"
   },
   "outputs": [],
   "source": [
    "params={'batch_size':32, 'latent':100, 'nz':100, 'nc':3 ,'ngf':128, 'ndf':128}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XMlOKiuAYyEY"
   },
   "source": [
    "# Define the Generator Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "xh4FMYoZYyEb"
   },
   "outputs": [],
   "source": [
    "class Generator(nn.Module):\n",
    "    def __init__(self, params):\n",
    "        super().__init__()\n",
    "\n",
    "        # Input is the latent vector Z.\n",
    "        self.tconv1 = nn.ConvTranspose2d(params['nz'], params['ngf']*8, kernel_size=4, stride=1, padding=0, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(params['ngf']*8)\n",
    "\n",
    "        # Input Dimension: (ngf*8) x 4 x 4\n",
    "        self.tconv2 = nn.ConvTranspose2d(params['ngf']*8, params['ngf']*4, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(params['ngf']*4)\n",
    "\n",
    "        # Input Dimension: (ngf*4) x 8 x 8\n",
    "        self.tconv3 = nn.ConvTranspose2d(params['ngf']*4, params['ngf']*2, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(params['ngf']*2)\n",
    "\n",
    "        # Input Dimension: (ngf*2) x 16 x 16\n",
    "        self.tconv4 = nn.ConvTranspose2d(params['ngf']*2, params['ngf'], kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.bn4 = nn.BatchNorm2d(params['ngf'])\n",
    "\n",
    "        # Input Dimension: (ngf) * 32 * 32\n",
    "        self.tconv5 = nn.ConvTranspose2d(params['ngf'], params['nc'], kernel_size=4, stride=2, padding=1, bias=False)\n",
    "\n",
    "        #Output Dimension: (nc) x 64 x 64\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.bn1(self.tconv1(x)))\n",
    "        x = F.relu(self.bn2(self.tconv2(x)))\n",
    "        x = F.relu(self.bn3(self.tconv3(x)))\n",
    "        x = F.relu(self.bn4(self.tconv4(x)))\n",
    "\n",
    "        x = torch.tanh(self.tconv5(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "A_izNjcgayGa"
   },
   "outputs": [],
   "source": [
    "generator = Generator(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-Ysej9wHa7Tg",
    "outputId": "afcb6e57-6933-47bc-a03a-0e03cd00fa7d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([32, 100, 1, 1]), Output shape: torch.Size([32, 3, 64, 64])\n"
     ]
    }
   ],
   "source": [
    "dummy_data =torch.rand(params['batch_size'],params['latent'],1,1)\n",
    "output = generator(dummy_data)\n",
    "print(f'Input shape: {dummy_data.shape}, Output shape: {output.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sW9xss_BYyEd"
   },
   "source": [
    "# Define the Discriminator Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "XMYUaVVNYyEe"
   },
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, params):\n",
    "        super().__init__()\n",
    "\n",
    "        # Input Dimension: (nc) x 64 x 64\n",
    "        self.conv1 = nn.Conv2d(params['nc'], params['ndf'], kernel_size=4, stride=2, padding=1, bias=False)\n",
    "\n",
    "        # Input Dimension: (ndf) x 32 x 32\n",
    "        self.conv2 = nn.Conv2d(params['ndf'], params['ndf']*2,  kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(params['ndf']*2)\n",
    "\n",
    "        # Input Dimension: (ndf*2) x 16 x 16\n",
    "        self.conv3 = nn.Conv2d(params['ndf']*2, params['ndf']*4, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.bn3 = nn.BatchNorm2d(params['ndf']*4)\n",
    "\n",
    "        # Input Dimension: (ndf*4) x 8 x 8\n",
    "        self.conv4 = nn.Conv2d(params['ndf']*4, params['ndf']*8, kernel_size=4, stride=2, padding=1, bias=False)\n",
    "        self.bn4 = nn.BatchNorm2d(params['ndf']*8)\n",
    "\n",
    "        # Input Dimension: (ndf*8) x 4 x 4\n",
    "        self.conv5 = nn.Conv2d(params['ndf']*8, 1, kernel_size=4, stride=1, padding=0, bias=False)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.leaky_relu(self.conv1(x), 0.2, True)\n",
    "        x = F.leaky_relu(self.bn2(self.conv2(x)), 0.2, True)\n",
    "        x = F.leaky_relu(self.bn3(self.conv3(x)), 0.2, True)\n",
    "        x = F.leaky_relu(self.bn4(self.conv4(x)), 0.2, True)\n",
    "\n",
    "        x = torch.sigmoid(self.conv5(x))\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "F8TvC5EGYyEf"
   },
   "outputs": [],
   "source": [
    "discriminator = Discriminator(params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "AbIFLWmzYyEh",
    "outputId": "756b097d-a067-479d-ed3d-472c3dbc89e1"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input shape: torch.Size([32, 3, 64, 64]), Output shape: torch.Size([32, 1, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "dummy_data =torch.rand(params['batch_size'],params['nc'],64,64)\n",
    "output = discriminator(dummy_data)\n",
    "print(f'Input shape: {dummy_data.shape}, Output shape: {output.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Vf94kJMsfT84"
   },
   "source": [
    "# Do Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cQgUahJ7gcyF"
   },
   "outputs": [],
   "source": [
    "# Apply the weights_init() function \n",
    "\n",
    "# Define loss function of the discriminator e.g. criterion = nn.BCELoss()\n",
    "# Define loss function of the generator e.g. criterion = nn.BCELoss()\n",
    "\n",
    "# Determine optimizer for the discriminator.\n",
    "# Determine optimizer for the generator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qwlUVItLfcBw"
   },
   "source": [
    "# Do training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o8Ev8HuwfSpa"
   },
   "outputs": [],
   "source": [
    "# for epoch in range(n_epochs):\n",
    "      # for i, data in enumerate(dataloader, 0):\n",
    "              # Train discriminator\n",
    "              # Train generator\n",
    "              # Check progress of training.  \n",
    "              # Save the losses for plotting.\n",
    "              # Check how the generator is doing by saving G's output on a fixed noise.     \n",
    "              # Save the model.\n",
    "\n",
    "# Save the final trained model."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "name": "DCGAN.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
